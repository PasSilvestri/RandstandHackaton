{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/miniconda3/envs/hackaton2023/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tain_path = './dataset/train_set.csv'\n",
    "data_test_path = './dataset/test_set.csv'\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(data_tain_path)\n",
    "data_test = pd.read_csv(data_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_offer</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Openjobmetis SpA ricerca, per importante azien...</td>\n",
       "      <td>Java Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La persona prescelta, diplomata o laureata in ...</td>\n",
       "      <td>Software Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sei un informatico o matematico con la passion...</td>\n",
       "      <td>Software Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ti occuperai della progettazione, realizzazion...</td>\n",
       "      <td>Programmer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stiamo cercando uno\\una sviluppatore\\sviluppat...</td>\n",
       "      <td>Programmer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>* Test JUnit\\n     * Git, La Ibs Srl è alla ri...</td>\n",
       "      <td>Java Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>La ricorsa, inserita all'interno di un team, l...</td>\n",
       "      <td>Programmer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>Sviluppatore Java Junior da inserire in attivi...</td>\n",
       "      <td>Java Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>La risorsa sarà inserita nei team di risorse d...</td>\n",
       "      <td>Web Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>Job summary Parola chiave: digitalizzazione! U...</td>\n",
       "      <td>Web Developer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1752 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Job_offer              Label\n",
       "0     Openjobmetis SpA ricerca, per importante azien...     Java Developer\n",
       "1     La persona prescelta, diplomata o laureata in ...  Software Engineer\n",
       "2     Sei un informatico o matematico con la passion...  Software Engineer\n",
       "3     Ti occuperai della progettazione, realizzazion...         Programmer\n",
       "4     Stiamo cercando uno\\una sviluppatore\\sviluppat...         Programmer\n",
       "...                                                 ...                ...\n",
       "1747  * Test JUnit\\n     * Git, La Ibs Srl è alla ri...     Java Developer\n",
       "1748  La ricorsa, inserita all'interno di un team, l...         Programmer\n",
       "1749  Sviluppatore Java Junior da inserire in attivi...     Java Developer\n",
       "1750  La risorsa sarà inserita nei team di risorse d...      Web Developer\n",
       "1751  Job summary Parola chiave: digitalizzazione! U...      Web Developer\n",
       "\n",
       "[1752 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_formatted = []\n",
    "for pd_data_row in data_train.iloc:\n",
    "    row = {'sentence': pd_data_row['Job_offer'], 'label': pd_data_row['Label']}\n",
    "    data_train_formatted.append(row)\n",
    "\n",
    "data_test_formatted = []\n",
    "for pd_data_row in data_test.iloc:\n",
    "    row = {'sentence': pd_data_row['Job_offer'], 'label': pd_data_row['Label']}\n",
    "    data_test_formatted.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_labels = sorted(list(set([r[\"label\"] for r in data_train_formatted])))\n",
    "data_test_labels = sorted(list(set([r[\"label\"] for r in data_test_formatted])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Java Developer',\n",
       " 'Programmer',\n",
       " 'Software Engineer',\n",
       " 'System Analyst',\n",
       " 'Web Developer']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Java Developer',\n",
       " 'Programmer',\n",
       " 'Software Engineer',\n",
       " 'System Analyst',\n",
       " 'Web Developer']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_label = data_train_labels\n",
    "label_to_id = {l:i for i,l in enumerate(id_to_label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JDataset():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "        \n",
    "    def create_collate_fn(self):\n",
    "        def collate_fn(batch):\n",
    "            batch_formatted = {}\n",
    "            batch_formatted['sentence'] = [sample['sentence'] for sample in batch]\n",
    "            batch_formatted['label'] = [sample['label'] for sample in batch]\n",
    "            return batch_formatted\n",
    "        return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = JDataset(data_train_formatted)\n",
    "dataset_test = JDataset(data_test_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=dataset_train.create_collate_fn(),\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "dataloader_dev = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=dataset_train.create_collate_fn(),\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code_files.models.transformer_classifier import TClassifier\n",
    "from code_files.utils.Trainer_nec import Trainer_nec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = TClassifier(\n",
    "    loss_fn = loss_function,\n",
    "    hparams = {\n",
    "        'transformer_name':\"xlm-roberta-base\",\n",
    "        'id_to_label': data_train_labels\n",
    "    },\n",
    "    fine_tune_transformer = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary(model, short = False):\n",
    "    \"\"\"prints the summary for a model\n",
    "\n",
    "    Args:\n",
    "        model (any): The torch model\n",
    "        short (bool, optional): If the print must be synthetic. Defaults to False.\n",
    "    \"\"\"\n",
    "    if not short:\n",
    "        print(model)\n",
    "        print('----------------------')\n",
    "    p = sum(p.numel() for p in model.parameters())\n",
    "    tp = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    ntp = p - tp\n",
    "    print('parameters:', f'{p:,}')\n",
    "    print('trainable parameters:', f'{tp:,}')\n",
    "    print('non-trainable parameters:', f'{ntp:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_pid = optim.SGD(model.parameters(), lr=0.0016, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: 278,047,493\n",
      "trainable parameters: 278,047,493\n",
      "non-trainable parameters: 0\n"
     ]
    }
   ],
   "source": [
    "print_summary(model, short = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in dataloader_dev:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': [\"Siamo alla ricerca di figure di Full Stack Developer da inserire all'interno del nostro Team di sviluppo per l'evoluzione di sistemi complessi in ambito gestionale e la realizzazione di funzionalità innovative per i nostri clienti. Facendo riferimento al proprio Team Leader e seguendo un processo ben strutturato, la figura ricercata dovrà seguire la progettazione, lo sviluppo ed il test degli interventi assegnati e la manutenzione dei moduli della suite.\"],\n",
       " 'label': ['Web Developer']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 23])\n",
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0480,  0.0987,  0.0585,  ..., -0.1251,  0.0694, -0.0113],\n",
      "         [ 0.0030, -0.0402, -0.0480,  ..., -0.0980, -0.0076, -0.1950],\n",
      "         [-0.0964, -0.0428,  0.0032,  ..., -0.1178, -0.0658,  0.1699],\n",
      "         ...,\n",
      "         [-0.0534, -0.0095,  0.0047,  ...,  0.0093, -0.0347,  0.1265],\n",
      "         [-0.1634, -0.0852,  0.2749,  ..., -0.3903, -0.2148,  0.1752],\n",
      "         [-0.0117, -0.0361, -0.0540,  ..., -0.4711, -0.0908,  0.0541]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-5.4394e-02,  2.3937e-01,  1.4170e-01,  4.8144e-01,  3.1102e-02,\n",
      "          3.4568e-01,  4.2155e-01, -4.2921e-01,  1.5022e-01, -1.5042e-01,\n",
      "          1.0694e-01,  1.3605e-01,  3.7633e-01,  3.5358e-01, -2.2302e-01,\n",
      "         -1.8314e-01,  2.0493e-01,  4.1246e-01, -4.4405e-02, -1.9544e-01,\n",
      "         -2.8153e-01,  3.5291e-01, -6.7343e-01, -5.5139e-01, -2.2133e-01,\n",
      "          5.8162e-01,  1.1278e-01, -3.1245e-01, -1.3727e-01,  6.5234e-01,\n",
      "          1.4592e-01,  4.5714e-01, -2.6892e-01,  1.1387e-01,  1.0753e-01,\n",
      "         -1.6174e-01,  4.1251e-01,  2.4039e-01,  4.7420e-01,  3.3069e-01,\n",
      "          1.0394e-01, -1.1308e-01, -1.4970e-01,  1.9907e-01,  2.4198e-01,\n",
      "         -2.3083e-01,  1.7588e-01, -2.2636e-02, -2.5608e-01,  4.0660e-01,\n",
      "          5.7915e-01, -2.4041e-01,  3.8627e-02,  2.6268e-02,  1.7773e-01,\n",
      "          1.3566e-01,  2.9330e-01, -3.2359e-01, -2.1207e-01, -5.2901e-01,\n",
      "         -1.0622e-02,  6.0050e-01,  4.3171e-01,  3.2008e-01,  3.0532e-01,\n",
      "         -5.4456e-01,  1.0858e-01, -6.0098e-02, -6.3210e-01,  1.5661e-01,\n",
      "          3.5877e-02, -3.3362e-01,  3.7625e-01,  8.8221e-02,  1.5498e-01,\n",
      "          4.5317e-02,  3.6546e-01,  1.5393e-01,  3.7542e-01,  2.8052e-01,\n",
      "          2.8346e-01, -3.2370e-01,  1.2869e-01, -2.1772e-01,  1.0114e-01,\n",
      "          6.6445e-01, -3.8972e-01,  7.5612e-01,  3.2850e-01,  3.0292e-01,\n",
      "         -1.8950e-01, -2.2637e-02, -3.2885e-01,  2.6749e-01, -3.9950e-01,\n",
      "          3.1374e-01, -3.6448e-01, -5.6965e-01,  9.6897e-02, -3.1820e-02,\n",
      "         -2.8073e-01, -3.8933e-01,  1.9478e-01, -4.6001e-01, -1.0383e-01,\n",
      "         -7.3569e-01,  5.1381e-01,  4.7123e-01, -1.9105e-01,  3.9038e-01,\n",
      "          1.7048e-01,  1.3787e-01,  3.2978e-01, -6.6879e-01,  1.0478e-01,\n",
      "          3.7030e-01,  5.2419e-01,  1.1607e-01,  1.9941e-02, -2.7397e-01,\n",
      "         -2.3440e-01,  5.4060e-01, -3.2320e-01, -1.4571e-01,  3.4977e-01,\n",
      "          9.8016e-02, -3.0061e-01,  6.1728e-01,  3.1985e-01, -3.8710e-02,\n",
      "          4.6081e-01, -3.2331e-01,  1.9855e-01, -5.9432e-01,  4.5736e-03,\n",
      "         -2.8735e-01,  5.1680e-01, -3.9133e-01, -3.4015e-02, -5.4548e-01,\n",
      "          3.5252e-01, -6.3310e-02, -2.0248e-01,  4.2499e-01, -1.8563e-01,\n",
      "          4.8294e-01,  5.1891e-01,  9.7161e-02, -2.7614e-01,  4.0427e-02,\n",
      "          6.1083e-01, -3.0308e-01,  1.8241e-01, -1.8563e-01,  1.4776e-01,\n",
      "          4.6115e-01, -5.0351e-02,  2.1135e-01, -1.8019e-01,  2.0297e-01,\n",
      "         -6.9975e-02,  2.9882e-01, -2.1108e-01, -3.4640e-01, -4.5808e-01,\n",
      "          2.2710e-01,  1.7556e-01,  7.5219e-01, -1.3148e-01,  2.4585e-01,\n",
      "         -2.8206e-01,  3.1002e-02,  4.8676e-01, -1.1953e-01, -2.3042e-01,\n",
      "         -5.4958e-01, -1.4622e-01, -3.6648e-01,  3.1244e-01, -1.2436e-02,\n",
      "         -3.5029e-01, -2.8648e-01,  7.2546e-01,  3.0028e-01, -1.6057e-01,\n",
      "          4.4075e-02, -2.1155e-01, -3.4192e-01, -2.5482e-02, -8.3039e-02,\n",
      "         -3.7232e-01, -1.3293e-01,  2.8263e-01, -4.9043e-01, -1.4234e-01,\n",
      "         -3.6300e-01, -7.9166e-02, -2.2339e-01, -3.4185e-01,  4.9511e-01,\n",
      "          3.9992e-01,  9.3803e-02, -4.1333e-01, -1.8949e-01,  3.1622e-02,\n",
      "          2.6185e-02, -2.6168e-01,  3.9149e-01, -2.6457e-02,  1.4447e-01,\n",
      "          4.2202e-02,  2.7750e-01, -5.8111e-02, -6.7616e-01, -3.9452e-01,\n",
      "          1.9443e-01, -7.5008e-01,  3.9542e-01, -2.5829e-01,  2.6932e-01,\n",
      "         -5.0820e-01,  3.8237e-01, -9.5297e-02, -5.4235e-01,  2.9733e-01,\n",
      "          5.9371e-01,  5.9029e-01, -5.1799e-01,  1.9225e-01, -7.6024e-02,\n",
      "          6.8233e-01, -2.1688e-02, -2.2702e-01, -2.0016e-01, -7.3000e-02,\n",
      "         -4.8913e-01,  3.6644e-01,  3.5717e-01, -4.9730e-01,  4.9259e-01,\n",
      "         -2.2749e-01,  5.5224e-02,  3.4299e-01,  8.8438e-02,  2.3071e-02,\n",
      "         -4.5130e-01,  3.3418e-01, -4.8612e-01,  2.9065e-01,  1.1932e-02,\n",
      "         -7.4183e-01, -3.0499e-01,  1.1685e-01,  6.3170e-01, -3.5213e-01,\n",
      "         -4.0102e-01, -4.1811e-02,  4.1674e-01, -5.3660e-01, -1.7609e-01,\n",
      "          1.3493e-01,  8.1252e-02, -8.6542e-02, -6.2457e-01, -4.4952e-01,\n",
      "          6.4297e-02, -3.9001e-02,  1.8988e-01, -2.3916e-01, -1.2275e-01,\n",
      "          4.9434e-01, -7.8845e-03,  2.5672e-01,  8.4976e-02, -3.4103e-01,\n",
      "          1.8867e-02,  1.3003e-01, -5.7174e-01,  2.5631e-01,  9.6768e-02,\n",
      "          7.2775e-01, -3.3996e-01,  3.3567e-01, -1.6345e-01,  1.6305e-01,\n",
      "         -4.9030e-02,  4.1172e-01,  9.2988e-02, -2.0091e-01,  4.6946e-01,\n",
      "         -5.1052e-01, -1.4880e-01,  1.4276e-01,  1.2818e-01, -3.1927e-01,\n",
      "          2.9027e-01, -2.8861e-01, -7.1165e-01,  1.6524e-01, -8.9873e-02,\n",
      "         -7.5479e-01, -7.7465e-01, -2.9249e-01, -2.8267e-01,  5.2620e-01,\n",
      "          2.5022e-01, -5.4328e-01, -3.2782e-03, -1.4779e-01,  1.8869e-02,\n",
      "          4.7706e-01,  2.8159e-01,  2.3048e-01,  2.8426e-02, -5.2257e-01,\n",
      "          3.3785e-01, -5.5839e-01, -5.1670e-03, -1.5662e-01,  3.2421e-01,\n",
      "          1.6560e-01,  2.3570e-01,  5.5520e-02,  6.8378e-01,  2.3224e-02,\n",
      "         -1.8657e-01, -4.2941e-01, -1.2067e-01, -3.4756e-02,  8.5601e-02,\n",
      "          4.1465e-01, -1.1527e-01, -3.8491e-01, -2.8696e-01,  1.4310e-01,\n",
      "          3.6627e-01,  5.2206e-01,  2.2942e-01, -3.1902e-01, -2.1697e-02,\n",
      "         -6.1382e-02, -4.8075e-01, -5.5927e-01,  3.2628e-01, -5.1255e-01,\n",
      "         -4.0310e-01,  1.8739e-01,  1.6778e-02, -4.4894e-01, -8.0260e-02,\n",
      "         -4.8346e-01,  4.2213e-01, -2.5232e-02, -4.6579e-01, -1.0809e-01,\n",
      "          2.7175e-01,  5.5088e-01,  2.7232e-02,  2.5166e-01,  1.0259e-01,\n",
      "         -3.4788e-02,  2.3140e-02,  1.6955e-01,  5.4414e-02,  1.4219e-01,\n",
      "         -5.6326e-01, -5.6140e-02, -2.4625e-01,  6.0002e-01,  1.0965e-01,\n",
      "          4.2612e-02,  6.4214e-02,  2.0486e-01, -3.2718e-01,  2.6510e-01,\n",
      "         -7.6202e-02, -3.4634e-01,  4.4344e-01, -2.2027e-01, -1.9331e-01,\n",
      "          5.0586e-01,  1.8965e-01, -9.2176e-02, -2.6848e-02,  1.4855e-01,\n",
      "          3.3503e-01,  5.3499e-01, -7.2352e-02,  6.3235e-01, -1.1124e-01,\n",
      "          5.4437e-01,  1.3362e-01, -1.3013e-01, -3.1338e-01,  4.3315e-02,\n",
      "         -5.9414e-01,  5.3461e-01, -4.7709e-01,  3.4025e-01, -4.8317e-02,\n",
      "         -3.9449e-01, -4.3572e-01,  6.2707e-01,  4.2654e-01,  4.0605e-01,\n",
      "          2.2890e-01,  1.0410e-01,  5.4076e-01, -6.5007e-01,  2.9263e-01,\n",
      "          3.4708e-01,  1.1226e-01,  1.6482e-01, -3.7900e-01, -1.4921e-01,\n",
      "         -1.6564e-01, -1.6832e-02, -2.0864e-01, -2.8861e-01, -1.8099e-01,\n",
      "          3.2118e-01, -5.6221e-01,  2.2165e-01,  7.4641e-01,  6.5936e-01,\n",
      "         -1.7164e-01,  1.4479e-01, -9.0965e-02, -2.3281e-01, -6.6216e-01,\n",
      "          1.1627e-02, -9.7735e-02, -4.7133e-01,  1.4496e-01, -1.5589e-01,\n",
      "         -5.2683e-01,  2.3491e-02,  1.8078e-01, -3.0994e-02,  6.0965e-02,\n",
      "         -1.8742e-01,  1.8428e-01,  4.1155e-01, -2.1881e-01, -1.0483e-01,\n",
      "         -2.7954e-01,  1.7110e-01,  3.6740e-01, -1.0078e-01,  4.4246e-02,\n",
      "          2.3143e-01, -3.3372e-01,  5.5517e-01,  1.9247e-01,  6.3919e-01,\n",
      "          3.1615e-01, -1.0702e-02,  2.2344e-01,  1.0755e-01, -3.5858e-01,\n",
      "          3.2254e-01, -3.8192e-01, -1.2275e-01,  8.9752e-02, -4.4992e-01,\n",
      "          1.9031e-01, -2.7017e-01, -7.3401e-01,  2.6981e-01,  3.6595e-01,\n",
      "         -2.4550e-01, -4.4954e-01,  1.1650e-02,  5.8606e-02, -4.6131e-01,\n",
      "         -1.1815e-01,  2.2801e-01, -1.1601e-01,  4.7524e-02,  2.4103e-01,\n",
      "          1.9727e-01, -2.3062e-04, -3.3883e-01,  3.1963e-01, -3.6267e-01,\n",
      "          6.5549e-01, -5.2101e-02,  7.0187e-02, -1.6359e-01, -3.9373e-01,\n",
      "         -1.0034e-01,  1.6087e-02,  1.6597e-01,  6.4570e-01, -1.8107e-01,\n",
      "          2.8463e-01,  1.6595e-01, -3.5567e-01, -4.2035e-01, -5.9713e-01,\n",
      "         -1.6336e-01,  1.0170e-01, -3.4136e-01,  2.3217e-01,  3.9867e-01,\n",
      "         -1.1021e-01, -1.0484e-01, -1.1528e-01,  1.5683e-01,  4.7090e-02,\n",
      "          3.3349e-01,  7.1090e-02, -5.6710e-01, -3.3190e-01, -7.3903e-02,\n",
      "         -2.5330e-01,  5.1850e-01,  3.7760e-01,  7.0477e-02,  1.7605e-01,\n",
      "          5.5260e-01, -3.1170e-01, -4.4472e-02,  1.9708e-01, -1.4980e-01,\n",
      "         -1.9259e-01, -3.1767e-01, -9.8714e-03,  4.7062e-01,  1.2380e-01,\n",
      "         -3.8227e-01, -5.1150e-01,  3.0760e-01,  2.8842e-01, -2.4167e-01,\n",
      "         -2.1336e-01,  6.6283e-01,  1.9839e-01, -9.3469e-02,  1.9253e-01,\n",
      "          4.1301e-01,  9.9139e-03,  3.3054e-01,  2.4802e-01,  7.6504e-01,\n",
      "          9.7126e-02, -1.2465e-01,  2.8122e-01, -5.1093e-01, -3.9809e-01,\n",
      "         -3.0628e-01,  6.6342e-01,  1.1608e-01,  3.4305e-01,  1.4092e-01,\n",
      "          8.7335e-02,  1.9212e-01,  2.9518e-01, -3.3662e-01, -2.8014e-01,\n",
      "          1.3420e-01,  4.8941e-01,  2.5951e-02, -2.8092e-01, -1.9011e-01,\n",
      "          4.1810e-01,  1.4876e-01, -4.5427e-01, -3.9044e-01,  4.2516e-01,\n",
      "          6.4106e-02, -4.6805e-02, -2.3288e-01,  2.8770e-01,  1.8415e-01,\n",
      "          2.8272e-01, -4.2585e-01, -5.1102e-01,  3.3269e-01, -3.1283e-01,\n",
      "         -2.0440e-01, -1.8641e-02,  7.4821e-01,  1.8737e-01, -4.5249e-02,\n",
      "          4.3320e-02, -3.0048e-02, -4.8952e-01, -4.5240e-01,  1.6462e-01,\n",
      "         -7.3671e-01,  2.1504e-01,  4.9532e-01, -9.0220e-02, -2.3263e-01,\n",
      "         -2.9500e-01,  4.0758e-02, -4.4835e-01,  2.0975e-01, -1.1744e-01,\n",
      "         -4.7441e-01,  2.6069e-01, -3.1272e-01, -4.3142e-02, -2.7005e-01,\n",
      "         -1.7957e-01,  3.0940e-01,  7.0046e-01, -4.9699e-01, -2.8722e-01,\n",
      "         -5.7016e-01,  1.5406e-01, -1.2843e-01,  5.4397e-02, -6.1348e-01,\n",
      "         -7.1954e-01,  3.6224e-02,  1.1137e-01,  5.7161e-01, -1.3527e-01,\n",
      "          1.5750e-01,  5.2482e-02,  1.1989e-01, -2.9058e-01,  8.0103e-01,\n",
      "          4.6591e-01, -3.1016e-01, -3.4164e-01, -5.6486e-01, -2.7469e-01,\n",
      "         -3.6147e-01, -3.7647e-01, -1.3902e-01, -3.9285e-01, -8.2948e-02,\n",
      "         -1.4280e-01,  8.0553e-01, -3.1396e-01, -3.5565e-01, -1.2335e-02,\n",
      "         -5.8355e-02, -8.6076e-02,  7.3345e-02,  2.3451e-02, -2.1436e-01,\n",
      "         -2.0305e-01,  2.8714e-01,  7.9491e-02, -1.8062e-02, -3.5943e-01,\n",
      "         -2.9186e-01, -5.9212e-01,  8.8198e-02,  2.0555e-01, -2.0469e-01,\n",
      "         -4.4071e-01,  5.8408e-01,  8.9449e-02,  1.7396e-01, -5.0652e-01,\n",
      "          4.3679e-01, -3.6216e-01,  2.1939e-01, -2.6262e-01, -2.6953e-02,\n",
      "         -3.0780e-01, -2.2807e-01, -1.0510e-01,  1.5694e-01, -2.0312e-02,\n",
      "          4.0996e-01, -1.8774e-01,  4.6235e-01,  1.0083e-01,  1.9997e-02,\n",
      "          1.8521e-01,  4.9635e-01,  1.0050e-01, -6.5631e-01, -2.3692e-01,\n",
      "         -7.8113e-01,  9.6777e-02,  1.3933e-02,  4.2644e-01, -6.2137e-01,\n",
      "         -7.5497e-02,  3.9613e-01,  8.7228e-02, -2.1365e-01,  2.0973e-01,\n",
      "         -3.5363e-01,  6.2670e-01,  4.4096e-01,  3.1073e-01, -5.9977e-02,\n",
      "          3.4567e-01,  6.3962e-01,  1.0100e-01, -1.2656e-01, -6.4138e-01,\n",
      "          4.0962e-03,  2.3809e-01,  1.5629e-01, -1.1752e-01,  1.5631e-01,\n",
      "         -6.7576e-01, -3.5080e-01,  3.7624e-01, -5.0919e-01, -7.8331e-02,\n",
      "          3.3608e-01, -1.0870e-01,  3.0408e-01, -6.0796e-01, -4.2047e-01,\n",
      "         -3.7829e-01, -1.9171e-01,  2.3147e-01, -4.3738e-01,  6.4602e-02,\n",
      "         -4.3597e-01, -9.1426e-02, -1.6923e-02, -1.1408e-02, -2.5958e-01,\n",
      "         -2.3505e-01, -3.8658e-01,  2.7412e-01, -1.2406e-01, -1.8192e-01,\n",
      "          4.6420e-02, -1.1191e-01,  4.0501e-02, -2.6642e-01, -1.1750e-01,\n",
      "         -3.0937e-01, -3.6420e-01, -2.1505e-01, -6.5631e-02, -2.3681e-01,\n",
      "          3.1394e-01, -4.0806e-01, -6.4205e-03, -5.0330e-02,  1.7892e-01,\n",
      "         -2.9145e-01,  8.1831e-01,  5.1157e-02, -1.2141e-01, -4.8721e-01,\n",
      "          2.2595e-01,  2.9583e-03, -4.3505e-01, -6.5094e-02, -1.1142e-01,\n",
      "         -1.9317e-01,  3.5198e-01,  5.6832e-01,  5.8963e-01, -5.3837e-01,\n",
      "         -1.2750e-01,  6.1885e-01, -2.6772e-01,  5.0677e-01, -4.2231e-01,\n",
      "         -7.4002e-02, -1.0133e-01,  1.4763e-01]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), hidden_states=(tensor([[[-0.1642,  0.1659, -0.1586,  ...,  0.0550, -0.1880,  0.0371],\n",
      "         [-0.3544, -0.0000,  0.5269,  ...,  0.3461, -0.2219, -0.0921],\n",
      "         [-0.2211, -0.0650, -0.0174,  ..., -0.1183, -0.2188,  0.4081],\n",
      "         ...,\n",
      "         [ 0.2889,  0.1201, -0.3172,  ...,  0.2839, -0.0826, -0.0000],\n",
      "         [ 0.1009,  0.1892, -0.1655,  ...,  0.1516,  0.2988,  0.0438],\n",
      "         [-0.0184,  0.2328,  0.0316,  ..., -0.0164, -0.0706, -0.0109]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>), tensor([[[-0.1084, -0.0355, -0.0548,  ..., -0.0976, -0.1017, -0.2892],\n",
      "         [-0.3749,  0.3559,  0.5064,  ...,  0.4432, -0.2184, -0.0260],\n",
      "         [-0.2994, -0.2838, -0.1603,  ..., -0.1981, -0.3552,  0.9649],\n",
      "         ...,\n",
      "         [ 0.3582,  0.1809, -0.2874,  ...,  0.9016, -0.3638, -0.1494],\n",
      "         [-0.0223,  0.2176, -0.0867,  ...,  0.6266,  0.2439,  0.2390],\n",
      "         [-0.1222,  0.1449,  0.1795,  ...,  0.0360, -0.0230, -0.0166]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0229,  0.0060, -0.0021,  ..., -0.0511, -0.0312, -0.0357],\n",
      "         [-0.1736,  0.5558,  0.7585,  ...,  0.7724, -0.4262,  0.0739],\n",
      "         [-0.4713,  0.0170,  0.0730,  ...,  0.2506, -0.5578,  0.9958],\n",
      "         ...,\n",
      "         [ 0.3211,  0.6619, -0.0834,  ...,  0.9055,  0.0424,  0.1300],\n",
      "         [ 0.1167,  0.6839,  0.1335,  ...,  0.6268,  0.3499,  0.4705],\n",
      "         [-0.1025,  0.4371,  0.1273,  ...,  0.5675, -0.0147, -0.1620]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0312, -0.0160, -0.0766,  ..., -0.0633, -0.0359, -0.0511],\n",
      "         [-0.2526, -0.2221,  0.3886,  ...,  0.4254, -0.1011, -0.6570],\n",
      "         [-0.3848,  0.0230, -0.0556,  ...,  0.2399, -0.1959,  0.7508],\n",
      "         ...,\n",
      "         [ 0.6637,  0.5848, -0.0974,  ...,  1.1277,  0.3074,  0.2211],\n",
      "         [-0.0462,  0.5250,  0.2525,  ...,  0.5808,  0.3787,  0.2702],\n",
      "         [-0.5321,  0.8222, -0.4123,  ...,  0.6299, -0.3913, -0.2058]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0122, -0.0100, -0.0172,  ..., -0.1019, -0.1152, -0.1317],\n",
      "         [-0.1987, -0.0067,  0.2801,  ...,  0.2936, -0.0518, -0.7239],\n",
      "         [-0.3091,  0.1602,  0.1828,  ...,  0.1970, -0.2964,  0.6270],\n",
      "         ...,\n",
      "         [ 0.4310,  0.0597, -0.0309,  ...,  0.9134,  0.0187,  0.2673],\n",
      "         [-0.2323,  0.3923,  0.1480,  ...,  0.5886, -0.0419,  0.1305],\n",
      "         [-1.1825,  0.2084, -0.4380,  ...,  0.6828,  0.0188, -0.3612]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0086,  0.0136,  0.0162,  ..., -0.0553, -0.0387, -0.0841],\n",
      "         [-0.2259,  0.1936,  0.3393,  ...,  0.3627, -0.1228, -0.7112],\n",
      "         [ 0.0197,  0.0156, -0.0624,  ...,  0.2420, -0.1823,  0.6305],\n",
      "         ...,\n",
      "         [ 0.4732,  0.3337, -0.0702,  ...,  1.4865, -0.1241,  0.6890],\n",
      "         [-0.1095,  0.1609, -0.0497,  ...,  0.6084, -0.0555,  0.1984],\n",
      "         [-0.8936,  0.0583, -0.1000,  ...,  0.6258, -0.0316, -0.4235]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 2.6988e-02,  1.4857e-02,  3.4456e-02,  ..., -4.0772e-02,\n",
      "          -2.8973e-03, -3.4648e-02],\n",
      "         [-2.8050e-01,  2.0997e-01,  2.4422e-01,  ...,  3.8012e-01,\n",
      "          -3.9135e-01, -1.0467e+00],\n",
      "         [ 1.0854e-03, -2.1514e-01,  4.8105e-01,  ...,  1.7850e-01,\n",
      "          -4.8906e-01,  6.4132e-01],\n",
      "         ...,\n",
      "         [ 2.6915e-01,  1.8760e-01,  4.4488e-02,  ...,  1.4691e+00,\n",
      "          -2.4526e-01,  8.1952e-01],\n",
      "         [-1.0761e-01,  5.0185e-02, -2.7737e-02,  ...,  6.2132e-01,\n",
      "          -4.7733e-02,  3.6394e-01],\n",
      "         [-2.8553e-01,  1.3102e-02,  1.1046e-01,  ...,  3.0480e-01,\n",
      "          -7.4183e-02, -1.4988e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0224, -0.0071, -0.0063,  ..., -0.0389, -0.0122, -0.0443],\n",
      "         [-0.4201,  0.1767,  0.5207,  ...,  0.3428, -0.3772, -0.9440],\n",
      "         [-0.0388, -0.0507,  0.5230,  ...,  0.1400, -0.2907,  0.5563],\n",
      "         ...,\n",
      "         [ 0.2680, -0.0200, -0.0759,  ...,  1.5202, -0.3628,  0.7088],\n",
      "         [-0.3441, -0.1763, -0.1235,  ...,  0.6256, -0.0670,  0.3239],\n",
      "         [-0.1421, -0.0267,  0.0415,  ...,  0.1171, -0.0538, -0.1392]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0110,  0.0041,  0.0271,  ..., -0.0234, -0.0053, -0.0092],\n",
      "         [-0.8891,  0.1847,  0.1646,  ...,  0.2638, -0.5397, -1.3973],\n",
      "         [ 0.0630, -0.0426,  0.5815,  ...,  0.0905, -0.5635,  0.5608],\n",
      "         ...,\n",
      "         [ 0.0657, -0.2656,  0.2463,  ...,  1.4791, -0.4618,  0.7836],\n",
      "         [-0.1239, -0.0424, -0.0391,  ...,  0.3114, -0.2853,  0.2975],\n",
      "         [-0.1280, -0.0289, -0.0516,  ...,  0.0729, -0.0336, -0.0269]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0658,  0.0042, -0.0042,  ..., -0.0467,  0.0215, -0.1180],\n",
      "         [-0.7749, -0.0894,  0.0850,  ...,  0.2353, -0.2316, -1.3914],\n",
      "         [-0.1441, -0.0639,  0.1397,  ...,  0.0248, -0.2988,  0.4690],\n",
      "         ...,\n",
      "         [-0.0321, -0.0196, -0.1109,  ...,  1.4065, -0.2714,  1.1694],\n",
      "         [-0.1488, -0.2808, -0.1904,  ...,  0.3025, -0.0938,  0.3005],\n",
      "         [-0.0975,  0.0262, -0.0022,  ..., -0.0681, -0.0243, -0.1045]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-4.8137e-02,  5.6741e-03, -2.1798e-02,  ..., -9.3275e-03,\n",
      "          -2.8774e-02, -1.0656e-01],\n",
      "         [-7.5896e-01, -5.5184e-01,  6.5346e-04,  ...,  2.0240e-01,\n",
      "          -1.7991e-02, -1.1476e+00],\n",
      "         [-2.3060e-01, -1.7570e-01,  2.2254e-01,  ...,  8.3614e-02,\n",
      "          -2.9474e-01,  3.7960e-01],\n",
      "         ...,\n",
      "         [-4.7825e-01,  1.8304e-01,  2.8174e-01,  ...,  8.4265e-01,\n",
      "          -1.9521e-01,  1.0495e+00],\n",
      "         [-2.2874e-01, -1.8579e-01,  1.3733e-01,  ...,  1.3443e-01,\n",
      "          -3.7305e-01,  2.5547e-01],\n",
      "         [-1.6579e-02,  2.8252e-02,  3.2659e-02,  ..., -1.3007e-02,\n",
      "           4.5021e-02, -3.5946e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-3.1985e-02, -2.6687e-03,  3.9610e-04,  ..., -1.1169e-03,\n",
      "           3.3268e-02, -7.3139e-02],\n",
      "         [-2.4459e-01, -4.3551e-01, -1.1117e-01,  ..., -3.7338e-02,\n",
      "          -6.5166e-02, -9.6215e-01],\n",
      "         [-2.1613e-01, -3.5402e-01, -2.8983e-03,  ..., -1.1836e-02,\n",
      "          -2.8240e-01,  4.0054e-01],\n",
      "         ...,\n",
      "         [-3.3378e-01,  1.4315e-01,  2.7559e-01,  ...,  5.9710e-01,\n",
      "          -2.5371e-01,  9.1053e-01],\n",
      "         [-1.1550e-01, -6.6245e-02,  2.0318e-01,  ...,  5.4570e-03,\n",
      "          -5.7338e-02,  8.6262e-02],\n",
      "         [-1.5789e-02, -3.2786e-02, -8.8456e-03,  ..., -2.4075e-02,\n",
      "          -1.5654e-02,  9.7934e-03]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0480,  0.0987,  0.0585,  ..., -0.1251,  0.0694, -0.0113],\n",
      "         [ 0.0030, -0.0402, -0.0480,  ..., -0.0980, -0.0076, -0.1950],\n",
      "         [-0.0964, -0.0428,  0.0032,  ..., -0.1178, -0.0658,  0.1699],\n",
      "         ...,\n",
      "         [-0.0534, -0.0095,  0.0047,  ...,  0.0093, -0.0347,  0.1265],\n",
      "         [-0.1634, -0.0852,  0.2749,  ..., -0.3903, -0.2148,  0.1752],\n",
      "         [-0.0117, -0.0361, -0.0540,  ..., -0.4711, -0.0908,  0.0541]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)), past_key_values=None, attentions=None, cross_attentions=None)\n",
      "torch.Size([1, 291])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 4.00 GiB total capacity; 3.34 GiB already allocated; 0 bytes free; 3.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[39m=\u001b[39m Trainer_nec()\n\u001b[0;32m----> 3\u001b[0m history \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m      4\u001b[0m     model, optimizer_pid, dataloader_train, dataloader_dev,\n\u001b[1;32m      5\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m      6\u001b[0m     save_best\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[1;32m      7\u001b[0m     min_score\u001b[39m=\u001b[39;49m\u001b[39m0.8\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m     save_path_name\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39m'\u001b[39;49m\u001b[39mcheckpoints/transformer_classifier/\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtransformer.pth\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m      9\u001b[0m     saved_history\u001b[39m=\u001b[39;49mhistory\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m/mnt/c/Users/lapos/Desktop/hackaton2023/RandstandHackaton/code_files/utils/Trainer.py:54\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, model, optimizer, train_dataloader, valid_dataloader, epochs, verbose, save_best, save_path_name, min_score, saved_history, device)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39m# batches of the training set\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m step, sample \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataloader):\n\u001b[0;32m---> 54\u001b[0m     dict_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_forward(model, sample, device, optimizer \u001b[39m=\u001b[39;49m optimizer) \u001b[39m# override\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     losses\u001b[39m.\u001b[39mappend(dict_out[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     57\u001b[0m mean_loss \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(losses) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(losses)\n",
      "File \u001b[0;32m/mnt/c/Users/lapos/Desktop/hackaton2023/RandstandHackaton/code_files/utils/Trainer_nec.py:29\u001b[0m, in \u001b[0;36mTrainer_nec.compute_forward\u001b[0;34m(self, model, sample, device, optimizer)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39m# outputs\u001b[39;00m\n\u001b[1;32m     27\u001b[0m labels_raw \u001b[39m=\u001b[39m sample[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 29\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(definition)\n\u001b[1;32m     31\u001b[0m predictions_raw \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mprocess_predictions(predictions)\n\u001b[1;32m     33\u001b[0m labels_processed \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor([ \n\u001b[1;32m     34\u001b[0m     model\u001b[39m.\u001b[39mhparams[\u001b[39m\"\u001b[39m\u001b[39mlabel_to_id\u001b[39m\u001b[39m\"\u001b[39m][v] \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m labels_raw \n\u001b[1;32m     35\u001b[0m ])\n",
      "File \u001b[0;32m/mnt/c/Users/lapos/Desktop/hackaton2023/RandstandHackaton/code_files/models/transformer_classifier.py:71\u001b[0m, in \u001b[0;36mTClassifier.forward\u001b[0;34m(self, text, text_pair, is_split_into_words)\u001b[0m\n\u001b[1;32m     61\u001b[0m batch_encoding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer(\n\u001b[1;32m     62\u001b[0m     text, text_pair,\n\u001b[1;32m     63\u001b[0m     return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m \u001b[39m# Warning!\u001b[39;00m\n\u001b[1;32m     67\u001b[0m )\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     69\u001b[0m \u001b[39mprint\u001b[39m(batch_encoding[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 71\u001b[0m transformer_outs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbatch_encoding)\n\u001b[1;32m     73\u001b[0m \u001b[39mprint\u001b[39m(transformer_outs)\n\u001b[1;32m     75\u001b[0m \u001b[39m# number of hidden states to consider from the transformer\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hackaton2023/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hackaton2023/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:854\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    845\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    847\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    848\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    849\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    852\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    853\u001b[0m )\n\u001b[0;32m--> 854\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    855\u001b[0m     embedding_output,\n\u001b[1;32m    856\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    857\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    858\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    859\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m    860\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    861\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    862\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    863\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    864\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    865\u001b[0m )\n\u001b[1;32m    866\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    867\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hackaton2023/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hackaton2023/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:528\u001b[0m, in \u001b[0;36mXLMRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    519\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    520\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    521\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    525\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    526\u001b[0m     )\n\u001b[1;32m    527\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 528\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    529\u001b[0m         hidden_states,\n\u001b[1;32m    530\u001b[0m         attention_mask,\n\u001b[1;32m    531\u001b[0m         layer_head_mask,\n\u001b[1;32m    532\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    533\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    534\u001b[0m         past_key_value,\n\u001b[1;32m    535\u001b[0m         output_attentions,\n\u001b[1;32m    536\u001b[0m     )\n\u001b[1;32m    538\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    539\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/hackaton2023/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hackaton2023/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:412\u001b[0m, in \u001b[0;36mXLMRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    401\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    402\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    409\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    410\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    411\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 412\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    413\u001b[0m         hidden_states,\n\u001b[1;32m    414\u001b[0m         attention_mask,\n\u001b[1;32m    415\u001b[0m         head_mask,\n\u001b[1;32m    416\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    417\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    418\u001b[0m     )\n\u001b[1;32m    419\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    421\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hackaton2023/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hackaton2023/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:339\u001b[0m, in \u001b[0;36mXLMRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    330\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    331\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    338\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 339\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    340\u001b[0m         hidden_states,\n\u001b[1;32m    341\u001b[0m         attention_mask,\n\u001b[1;32m    342\u001b[0m         head_mask,\n\u001b[1;32m    343\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    344\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    345\u001b[0m         past_key_value,\n\u001b[1;32m    346\u001b[0m         output_attentions,\n\u001b[1;32m    347\u001b[0m     )\n\u001b[1;32m    348\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m    349\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hackaton2023/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hackaton2023/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:218\u001b[0m, in \u001b[0;36mXLMRobertaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    216\u001b[0m     value_layer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([past_key_value[\u001b[39m1\u001b[39m], value_layer], dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    217\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 218\u001b[0m     key_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey(hidden_states))\n\u001b[1;32m    219\u001b[0m     value_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue(hidden_states))\n\u001b[1;32m    221\u001b[0m query_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(mixed_query_layer)\n",
      "File \u001b[0;32m~/miniconda3/envs/hackaton2023/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hackaton2023/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 4.00 GiB total capacity; 3.34 GiB already allocated; 0 bytes free; 3.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "trainer = Trainer_nec()\n",
    "\n",
    "history = trainer.train(\n",
    "    model, optimizer_pid, dataloader_train, dataloader_dev,\n",
    "    epochs=100, device=device,\n",
    "    save_best=True, \n",
    "    min_score=0.8,\n",
    "    save_path_name=os.path.join('checkpoints/transformer_classifier/', f'transformer.pth'),\n",
    "    saved_history=history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackaton2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
